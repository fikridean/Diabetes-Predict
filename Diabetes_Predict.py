# -*- coding: utf-8 -*-
"""Diabetes_Predict.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b0vebND2v6RYrWINwIXHdHBcAJJ-VjLw

# Proyek Machine Learning Dicoding: ***Diabetes Prediction Classification***

## *Personal Data*

*   ***Name***        : Fikri Dean Radityo
*   ***Username***    : fikridean11
*   ***Email***       : fikrideanradityo@gmail.com
*   **Linkedin**    : https://www.linkedin.com/in/fikridean/
*   ***University***  : Universitas Islam Negeri Syarif Hidayatullah Jakarta

## *Import Libraries*
"""

# Commented out IPython magic to ensure Python compatibility.
import gdown
import matplotlib.pyplot as plt
# %matplotlib inline
import pandas as pd
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

from imblearn.over_sampling import SMOTE

"""# *Data Understanding*

## *Import Dataset*

*   ***Dataset source***: https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset
*   ***Dataset name***: Diabetes prediction dataset

*Dataset* yang digunakan untuk pembangunan model machine learning ini adalah *dataset* "Diabetes prediction *dataset*" yang tersedia di situs web Kaggle pada [tautan](https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset) ini. *Dataset* tersebut adalah *dataset* kuantitatif yang berisi kolom-kolom yang dapat digunakan untuk memprediksi apakah seseorang menderita diabetes berdasarkan data-data yang diberikan. *Dataset* ini memiliki 10000 baris dan 9 kolom data.

*Dataset* ini cocok untuk membangun model *supervised learning*, khususnya *binary classification*. Dalam kasus ini adalah melakukan klasifikasi penderita diabetes berdasarkan delapan fitur.

Berikut ini adalah informasi lainnya mengenai *dataset* tersebut:

Variabel-variabel pada *Dataset* "Diabetes prediction dataset" adalah sebagai berikut:

*   `Jenis Kelamin (gender)`: Jenis kelamin mengacu pada jenis kelamin biologis individu, yang dapat memengaruhi kerentanan terhadap diabetes. Terdapat tiga kategori: laki-laki, perempuan, dan lainnya.

*   `Umur (age)`: Umur merupakan faktor penting karena diabetes lebih sering terdiagnosis pada orang dewasa yang lebih tua. Rentang usia dalam *dataset* adalah 0-80 tahun.

*   `Hipertensi (hypertension)`: Hipertensi adalah kondisi medis di mana tekanan darah di arteri terus-menerus tinggi. Nilai 0 menunjukkan tidak memiliki hipertensi, sedangkan nilai 1 berarti memiliki hipertensi.

*   `Penyakit Jantung (heart_disease)`: Riwayat merokok dianggap sebagai faktor risiko untuk diabetes dan dapat memperburuk komplikasi yang terkait dengan diabetes. Dalam *dataset*, terdapat lima kategori: tidak saat ini (not current), mantan perokok (former), tidak ada informasi (No Info), perokok saat ini (current), tidak pernah merokok (never), dan pernah merokok (ever).

*   `Riwayat Merokok (smoking_history)`: Penyakit jantung adalah kondisi medis yang juga berhubungan dengan peningkatan risiko diabetes. Nilai 0 menunjukkan tidak memiliki penyakit jantung, sedangkan nilai 1 berarti memiliki penyakit jantung.

*   `BMI (bmi)`: Indeks Massa Tubuh adalah ukuran yang digunakan untuk menilai apakah berat badan seseorang berada dalam kategori sehat berdasarkan tinggi badannya.

*   `Kadar HbA1c (HbA1c_level)`: Kadar HbA1c mencerminkan kadar gula darah rata-rata seseorang dalam beberapa bulan terakhir.

*   `Kadar Glukosa Darah (blood_glucose_level)`: Kadar glukosa darah mengacu pada jumlah gula yang ada dalam darah seseorang pada suatu waktu tertentu.

*   `Diabetes (age)`: Diabetes adalah kondisi kesehatan kronis yang terjadi ketika kadar gula darah seseorang terlalu tinggi. Nilai 0 menunjukkan tidak menderita diabetes, sedangkan nilai 1 berarti menderita diabetes.
"""

# Google Drive CSV file link pattern
dataset_file_id = "1Ov0wv_gTFcivDqMh79l5_r2z-sVovA64"

# Target destination
destination = "/content/diabetes.csv"

# Download the dataset
gdown.download(f"https://drive.google.com/uc?id={dataset_file_id}", destination, quiet=False)

# Load the dataset
dataset = "diabetes.csv"

# Create Dataframe
df = pd.read_csv(dataset)

df

"""## *Exploratory Data Analysis*

***Exploratory Data Analysis*** (EDA) adalah tahap awal dalam mengeksplorasi data untuk menganalisis karakteristik, mengidentifikasi pola, menemukan anomali, dan memverifikasi asumsi-asumsi yang ada dalam data.
"""

# Check dataset rows and columns

df.shape

df.keys()

"""Berdasarkan output kode di atas didapatkan informasi berikut:

*   Jumlah baris dan kolom adalah 100000 baris dan 9 kolom.
*   Terdapat 9 kolom fitur yaitu `gender`, `age`, `hypertension`, `heart_disease`, `smoking_history`, `bmi`, `HbA1c_level`, dan `blood_glucose_level` serta 1 kolom label yaitu `diabetes`.


"""

# Dataset features data type

df.info()

"""Berdasarkan output kode diatas didapatkan informasi berikut:

*   Terdapat 2 kolom dengan tipe object, yaitu: `gender` dan `smoking_history`. Kolom ini merupakan categorical features (fitur non-numerik).
*   Terdapat 3 kolom numerik dengan tipe data float64 yaitu: `age`, `bmi`, dan `HbA1c_level`.
*   Terdapat 4 kolom numerik dengan tipe data int64, yaitu: `hypertension`, `heart_disease`, `blood_glucose_level`, dan `diabetes`. Kolom `diabetes` merupakan label.


"""

# Get statistic of the data

df.describe()

"""Fungsi describe() memberikan informasi statistik pada masing-masing kolom, antara lain:

*   **Count**  adalah jumlah sampel pada data.
*   **Mean** adalah nilai rata-rata.
*   **Std** adalah standar deviasi.
*   **Min** yaitu nilai minimum setiap kolom.
*   **25%** adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
*   **50%** adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
*   **75%** adalah kuartil ketiga.
*   **Max** adalah nilai maksimum.
"""

# Check if there are missing values in the DataFrame

missing_values = df.isnull().sum()
missing_values

# Check if there are any missing values in the entire DataFrame

any_missing = df.isnull().values.any()
print(any_missing)

"""Berdasarkan output kode diatas, dapat dilihat bahwa tidak ada baris yang memiliki baris yang berisi value *null* atau *missing value*

## Data Visualization

### *Univariate Analysis*

*Univariate analysis* adalah analisis yang hanya melibatkan satu variabel (*feature*) pada satu waktu. Tujuan utamanya adalah memahami distribusi, karakteristik, dan pola variabel tersebut.

Fitur-fitur dibagi menjadi fitur kategorikan dan fitur numerikal untuk mempermudah analisis yang akan dilakukan
"""

# Gather features based on categorical or numerical type

categorical_features = ['gender', 'smoking_history']
numerical_features = ['age', 'hypertension', 'heart_disease', 'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes']

"""Fungsi `CoundAndPlot` dibuat guna mengurangi redudansi kode"""

# Create function to count and plot categorical data

def CountAndPlot(feature):
  count = df[feature].value_counts()
  percent = 100*df[feature].value_counts(normalize=True)
  samples = pd.DataFrame({'Sample Count':count, 'Percentage':percent.round(1)})
  print(samples)
  count.plot(kind='bar', title=feature)

# Count and plot gender data

CountAndPlot(categorical_features[0])

"""Berdasarkan grafik diatas, dapat dilihat bahwa jumlah data berjenis kelamin **perempuan berjumlah 58552 (58,6 persen)** dan data berjenis kelamin **laki-laki berjumlah 41430 (41,4 persen)**. Selain itu terdapat juga data berjenis kelamin lainnya (*other*)"""

# Count and plot smoking history

CountAndPlot(categorical_features[1])

"""Berdasarkan grafik diatas, dapat dilihat bahwa jumlah data yang **tidak terdapat informasi mengenai riwayat merokok** dan data yang memiliki riwayat **tidak pernah merokok** mendominasi pada *dataset*"""

# Observe the relationship between numeric features

df.hist(bins=50, figsize=(20,15))
plt.show()

"""Fitur-fitur yang termasuk ke dalam data numerikal dapat dilihat pada histogram diatas

### *Multivariate analysis*

*Multivariate analysis* adalah analisis yang melibatkan dua atau lebih variabel secara bersamaan. Tujuan utamanya adalah untuk memahami hubungan atau interaksi antara variabel-variabel tersebut.
"""

for col in categorical_features:
    sns.catplot(
        x=col,
        y="diabetes",
        kind="bar",
        dodge=False,
        height=4,
        aspect=3,
        data=df,
        palette="Set3",
        hue=col,
        legend=False
    )
    plt.title("Rata-rata 'diabetes' Relatif terhadap - {}".format(col))

"""**Rata-rata diabetes relatif terhadap jenis kelamin**

Terlihat bahwa jenis kelamin memiliki pengaruh terhadap rata-rata diabetes. Data berjenis kelamin kaki-laki memiliki rata-rata diabetes yang lebih tinggi dibandingkan data berjenis kelamin perempuan, sementara data berjenis kelamin lainnya (*other*) memiliki rata-rata yang sangat rendah atau hampir nol.

**Rata-rata diabetes relatif terhadap riwayat merokok**

Data yang pernah menjadi perokok (former) memiliki rata-rata diabetes tertinggi dibandingkan kategori lain, sementara data yang tidak memiliki informasi mengenai riwayat merokok memiliki rata-rata diabetes terendah.

Dari kedua grafik diatas, dapat disimpulkan bahwa faktor jenis kelamin dan riwayat merokok dapat menjadi faktor risiko penting yang memengaruhi kemungkinan terkena diabetes.
"""

sns.pairplot(df, diag_kind = 'kde')

sns.pairplot(df, diag_kind = 'kde', hue ='diabetes')

"""Pada gambar kedua (yang menekankan perbedaan warna antara diabetes dan tidak),
Dapat terlihat bahwa variabel seperti HbA1c_level dan blood_glucose_level memiliki hubungan kuat dengan diabetes, di mana nilai yang lebih tinggi pada kedua variabel ini sering dikaitkan dengan kasus diabetes.
"""

plt.figure(figsize=(10, 8))
correlation_matrix = df[numerical_features].corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Pada correlation matrix diatas, dapat dilihat bahwa fitur HbA1c_level dan blood_glucose_level memiliki pengaruh besar untuk prediksi diabetes. Hal ini bisa diambil dengan melihat bahwa terdapat perbedaan signifikan antara penderita diabetes dan tidak pada variabel-variabel tersebut.

## *Data Preperation*

### *Data Cleaning*

*Data Cleaning* adalah proses memperbaiki atau menghapus data yang salah, rusak, memiliki format yang tidak sesuai, duplikat, atau tidak lengkap dalam sebuah *dataset*. Ketika menggabungkan berbagai sumber data, peluang terjadinya duplikasi atau pelabelan yang salah menjadi lebih besar.

**Alasan**: Proses *Data Cleaning* harus dilakukan untuk memeriksa, memperbaiki, dan memastikan bahwa data yang digunakan sudah siap digunakan dan tidak terdapat potensi kesalahan

***Removal Duplicates and NaN Data***

Menghapus entri duplikat memastikan bahwa dataset menjadi unik dan bebas dari baris yang redundan. Duplikasi dapat terjadi akibat kesalahan pengumpulan data, penggabungan dataset, atau duplikasi yang tidak disengaja.

*NaN* (*Not a Number*) adalah nilai yang mewakili data yang hilang atau tidak terdefinisi dalam sebuah dataset. Penanganan data *NaN* sangat penting untuk memastikan bahwa perhitungan dan analisis tidak menjadi bias atau menghasilkan hasil yang tidak akurat.

**Alasan**: Proses ini perlu dilakukan guna membersihkan data yang berpotensi memunculkan kesalahan seperti value *NaN* dan menghilangkan data yang berpotensi menurunkan performa seperti data duplikat.
"""

# Drop duplicate and NaN
clean_df = df.drop_duplicates().dropna()

"""***One-Hot Encoding***

*One-hot encoding* adalah salah satu metode untuk mengubah data sehingga siap digunakan oleh algoritma dan menghasilkan prediksi yang lebih baik. Dalam metode ini, setiap nilai kategori diubah menjadi kolom kategori baru, kemudian diberikan nilai biner 1 atau 0 pada kolom-kolom tersebut.

**Alasan**: Proses ini perlu dilakukan karena algoritma dapat bekerja dengan baik untuk data numerikal sehingga data kategorikal harus diubah menjadi biner seperti 0 dan 1
"""

# One Hot Encoding
for col in categorical_features:
  clean_df = pd.concat([clean_df, pd.get_dummies(clean_df[col], prefix=col, dtype=int)],axis=1)

clean_df.drop(categorical_features, axis=1, inplace=True)

"""Mendapatkan informasi dan Memeriksa *value* dari variable `clean_df` setelah dilakukannya proses *Removal Duplicates and NaN Data* dan *One-Hot Encoding*"""

clean_df.info()

clean_df.head()

"""***Handle Imbalance Data***

*Imbalanced data* adalah istilah yang digunakan untuk menggambarkan jenis dataset tertentu dan menjadi tantangan utama dalam masalah klasifikasi. *Imbalanced data* mengacu pada situasi di mana jumlah sampel pada setiap kelas sangat bervariasi.

"""

counts = clean_df['diabetes'].value_counts()
labels = ['Diabetes' if val == 1 else 'No Diabetes' for val in counts.index]

plt.figure(figsize=(8, 8))
counts.plot.pie(
    autopct='%1.1f%%',
    labels=labels,
    startangle=90,
    colors=['green', 'red']
)
plt.title('Distribution of Diabetes')
plt.ylabel('')
plt.show()

"""Dari *pie chart* diatas dapat dilihat bahwa terdapat imbalance data pada *dataset* ini. Selanjutnya akan dilakukan *oversampling* untuk mengatasi *imbalance data* tersebut."""

# Drop the target column
X = clean_df.drop(['diabetes'], axis=1)
y = clean_df['diabetes']

# Apply SMOTE to balance the dataset
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

print(f"Resampled class distribution: {pd.Series(y_resampled).value_counts()}")

"""***Standardization***

Standarisasi adalah metode penskalaan fitur di mana nilai data diubah skala agar sesuai dengan distribusi antara 0 dan 1, menggunakan nilai rata-rata (*mean*) dan standar deviasi sebagai dasar untuk menghitung nilai tertentu. Jarak antar data kemudian digunakan untuk memetakan kesamaan dan perbedaan.
"""

# Scale the X values using scaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_resampled)

X_scaled

print(X_resampled.describe())     # Check for extreme values or outliers
print(y_resampled.value_counts()) # Check the class distribution in `y`

"""***Train Test Split***

*Train-test split* adalah metode sederhana untuk mengukur kinerja algoritma machine learning dalam prediksi dengan membandingkan hasil model yang dibuat dengan data yang belum pernah dilihat sebelumnya.

**Alasan**: Proses ini dilakukan dengan tujuan untuk melakukan evaluasi terhadap model yang akan dibuat dengan mengukur seberapa baik model dapat memprediksi data yang belum pernah dilihat (data yang tidak dimasukkan ke data latih melainkan ke data *test*).


"""

# Split the data for training and testing
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_resampled, test_size=0.2)

"""Data telah dibagi menjadi dua yaitu data latih sebesar 20% dan data *testing* sebesar 80% dari total keseluruhan data.

## *Modelling*

Setelah proses *Data Preparation* telah dilakukan, selanjutnya adalah proses *Modelling* yang dimana model akan dibuat dan melatih model tersebut dengan menggunakan data *training* serta menggunakan data *testing* untuk melakukan evaluasi terhadap model yang telah dibuat.

Pada proses *modelling* ini, tiga algoritma akan digunakan untuk melatih model. Berikut ketiga algoritma tersebut disertai dengan kelebihan dan kekurangan dari setiap algoritma:

- SVC (*Support Vector Classifier*)
  - Kelebihan:
    - Baik untuk data berdimensi tinggi.
    - Margin terbesar antara kelas.
    - Kuat terhadap overfitting.
  - Kekurangan:
    - Lambat untuk dataset besar.
    - Memerlukan tuning parameter yang hati-hati.
    - Kurang efisien untuk data besar karena berat di komputasi.

- *Random Forest*
  - Kelebihan:
    - Tahan terhadap overfitting.
    - Bisa menangani data hilang dan outliers.
    - Mudah menganalisis fitur penting.
  - Kekurangan:
    - Sulit diinterpretasi secara keseluruhan.
    - Waktu pelatihan lama.
    - Memerlukan banyak memori.

- *K-Nearest Neighbors* (KNN)
  - Kelebihan:
    - Sederhana dan mudah dipahami.
    - Tidak memerlukan pelatihan eksplisit.
    - Fleksibel dengan banyak tipe data.
  - Kekurangan:
    - Waktu inferensi lama.
    - Sensitif terhadap skala data.
    - Rentan terhadap noise dan data tidak seimbang.


Dari ketiga algoritma tersebut, akan dipilih model terbaik yang diukur melalui rata-rata metrik setelah masing-masing model dibuat, dilatih, dan dievaluasi.

**Model *machine learning* menggunakan algoritma `SVC`**

Parameter yang digunakan pada model yang menggunakan algoritma `SVC` adalah parameter default dari algoritma tersebut. Parameter yang digunakan adalah sebagai berikut:

- `C (Regularisasi)`: Parameter regularisasi yang mengontrol keseimbangan antara kesalahan pada data pelatihan dan penyederhanaan model (maksimalisasi margin). Nilai default dari parameter ini adalah `1.0`.
- `kernel`: Jenis fungsi kernel yang digunakan untuk memetakan data ke dimensi yang lebih tinggi. Nilai default dari parameter ini adalah `rbf`.
- `gamma`: Koefisien kernel untuk kernel 'rbf', 'poly', dan 'sigmoid'. Nilai default dari parameter ini adalah `scale`.
"""

svm_model = SVC()

svm_model.fit(X_train, y_train)

y_pred_train_svm = svm_model.predict(X_train)
y_pred_test_svm = svm_model.predict(X_test)

accuracy_train_svm = accuracy_score(y_pred_train_svm, y_train)
accuracy_test_svm = accuracy_score(y_pred_test_svm, y_test)

print('SVC - accuracy_train:', accuracy_train_svm)
print('SVC - accuracy_test:', accuracy_test_svm)

print('Classification Report:\n', classification_report(y_test, y_pred_test_svm))

"""Model SVM dengan konfigurasi **SVC** menunjukkan performa yang sangat baik pada *dataset*.

- Akurasi:
  - Data latih: **94,67%**
  - Data uji: **94,72%**
  - Hasil ini menunjukkan generalisasi yang kuat tanpa indikasi overfitting.

- Data Klasifikasi:
  - **Kelas 0** (Tidak Diabetes):
    - Presisi: **93%**
    - Recall: **97%**
    - F1-Score: **95%**
  - **Kelas 1** (Diabetes):
    - Presisi: **97%**
    - Recall: **93%**
    - F1-Score: **95%**

- Rata-rata metrik untuk seluruh kelas:
  - Presisi: **95%**
  - Recall: **95%**
  - F1-Score: **95%**

- *Dataset* berukuran **35.066 sampel**, dengan keseimbangan performa yang baik antara kedua kelas.

**Model *machine learning* menggunakan algoritma `Random Forest`**

Parameter yang digunakan pada model yang menggunakan algoritma `Random Forest` adalah parameter default dari algoritma tersebut. Parameter yang digunakan adalah sebagai berikut:

- `n_estimators`: Jumlah *tree* pada algoritma `Random Forest`. Semakin besar, semakin baik prediksi, tetapi membutuhkan waktu komputasi lebih lama. Nilai default dari parameter ini adalah `100`.
- `max_depth`: Kedalaman yang ditentukan untuk *tree*. Nilai default dari parameter ini adalah `None`.
- `min_samples_leaf`: Jumlah minimum sampel pada *tree*. Nilai default dari parameter ini adalah `1`.
- `min_samples_split`: Jumlah minimum sampel untuk membagi node internal. Nilai default dari parameter ini adalah `2`.
- `max_features`: Jumlah maksimum fitur yang dipertimbangkan untuk split. Nilai default dari parameter ini adalah `sqrt`.
"""

rf_model = RandomForestClassifier()

rf_model.fit(X_train, y_train)

y_pred_train_rf = rf_model.predict(X_train)
y_pred_test_rf = rf_model.predict(X_test)

accuracy_train_rf = accuracy_score(y_pred_train_rf, y_train)
accuracy_test_rf = accuracy_score(y_pred_test_rf, y_test)

print('Random Forest - accuracy_train:', accuracy_train_rf)
print('Random Forest - accuracy_test:', accuracy_test_rf)

print('Classification Report:\n', classification_report(y_test, y_pred_test_rf))

"""Model *Random Forest* menunjukkan performa yang sangat baik pada *dataset*.

- Akurasi:
  - Data latih: **99,96%**
  - Data uji: **97,92%**
  - Hasil ini menunjukkan bahwa model mampu menggeneralisasi dengan baik pada data uji.

- Data Klasifikasi:
  - **Kelas 0** (Tidak Diabetes):
    - Presisi: **97%**
    - Recall: **99%**
    - F1-Score: **98%**
  - **Kelas 1** (Diabetes):
    - Presisi: **99%**
    - Recall: **97%**
    - F1-Score: **98%**

- Rata-rata metrik untuk seluruh kelas:
  - Presisi: **98%**
  - Recall: **98%**
  - F1-Score: **98%**

- *Dataset* berukuran **35.066 sampel**, dengan performa yang sangat baik dan keseimbangan yang kuat antara kedua kelas.

**Model *machine learning* menggunakan algoritma `KNN`**

Parameter yang digunakan pada model yang menggunakan algoritma `KNN` adalah parameter default dari algoritma tersebut. Parameter yang digunakan adalah sebagai berikut:

- `n_neighbors`: Jumlah *neighbors* yang ditentukan. Nilai default dari parameter ini adalah `5`.
- `algorithm`: Algoritma pencarian *neighbors*. Nilai default dari parameter ini adalah `auto`.
"""

knn_model = KNeighborsClassifier()
knn_model.fit(X_train, y_train)

y_pred_train_knn = knn_model.predict(X_train)
y_pred_test_knn = knn_model.predict(X_test)

accuracy_train_knn = accuracy_score(y_pred_train_knn, y_train)
accuracy_test_knn = accuracy_score(y_pred_test_knn, y_test)

print('KNN - accuracy_train:', accuracy_train_knn)
print('KNN - accuracy_test:', accuracy_test_knn)
print('Classification Report:\n', classification_report(y_test, y_pred_test_knn))

"""Model KNN menunjukkan performa yang sangat baik pada *dataset*.

- Akurasi:
  - Data latih: **97,34%**
  - Data uji: **96,10%**
  - Hasil ini menunjukkan model dapat menggeneralisasi dengan baik pada data uji.

- Data Klasifikasi:
  - **Kelas 0** (Tidak Diabetes):
    - Presisi: **96%**
    - Recall: **96%**
    - F1-Score: **96%**
  - **Kelas 1** (Diabetes):
    - Presisi: **96%**
    - Recall: **96%**
    - F1-Score: **96%**

- Rata-rata metrik untuk seluruh kelas:
  - Presisi: **96%**
  - Recall: **96%**
  - F1-Score: **96%**

- *Dataset* berukuran **35.066 sampel**, dengan keseimbangan performa yang sangat baik antara kedua kelas.

Dari hasil pelatihan dan evaluasi masing-masing model dengan ketiga algoritma yang telah disebutkan sebelumnya, dapat dilihat bahwa algoritma *Random Forest* memiliki rata-rata metrik paling tinggi dari kedua algoritma lainnya. Berdasarkan kelebihan-kelebihan dari algoritma tersebut dan hasil akurasi yang memadai serta merupakan nilai tertinggi dibanding algoritma lainnya, algoritma *Random Forest* menjadi algoritma yang cocok untuk dijadikan sebagai solusi.

## *Evaluation*

Berdasarkan hasil dari proses *modelling* yang dimana telah dipilih model terbaik yaitu model yang menggunakan algoritma *Random Forest*. Metrik evaluasi yang akan digunakan adalah sebagai berikut:

1. **Accuracy**  
   - Mengukur proporsi prediksi yang benar dari total data.  
   - Formula:  
      **Accuracy = (TP + TN) / (TP + TN + FP + FN)**  

      Informasi:
      - TP: True Positive (prediksi benar kelas positif)
      - TN: True Negative (prediksi benar kelas negatif)
      - FP: False Positive (prediksi salah kelas positif)
      - FN: False Negative (prediksi salah kelas negatif)

2. **Precision**  
   - Mengukur seberapa akurat model dalam memprediksi kelas positif dengan menunjukkan seberapa banyak prediksi positif yang benar dari semua prediksi positif.
   - Formula:  
      **Precision = TP / (TP + FP)**

3. **Recall**  
   - Mengukur seberapa baik model mendeteksi kelas positif yang benar dengan menunjukkan seberapa banyak data positif yang benar-benar terdeteksi oleh model.
   - Formula:  
      **Recall = TP / (TP + FN)**  

4. **F1-Score**  
   - Rata-rata harmonis antara precision dan recall, memberikan keseimbangan antara keduanya. F1-Score digunakan ketika kita ingin keseimbangan antara precision dan recall.
   - Formula:  
      **F1-Score = 2 * (Precision * Recall) / (Precision + Recall)**  

5. **Support**  
   - Jumlah data sebenarnya untuk setiap kelas. Support memberikan informasi tentang jumlah sampel yang ada untuk masing-masing kelas dalam dataset.
"""

# Compute the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred_test_rf)

# Display the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=rf_model.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix - Random Forest Model")
plt.show()

y_pred_test_rf = rf_model.predict(X_test)
accuracy_test_rf = accuracy_score(y_pred_test_rf, y_test)
print('Random Forest - accuracy_test:', accuracy_test_rf)
print('Classification Report:\n', classification_report(y_test, y_pred_test_rf))

"""Berikut informasi yang didapatkan dari hasil *confusion matrix* dan *classification report*,

- **Akurasi**: **97.86%** pada data uji.
- **Precision**:
  - Kelas 0: **0.97**
  - Kelas 1: **0.99**
- **Recall**:
  - Kelas 0: **0.99**
  - Kelas 1: **0.97**
- **F1-score**:
  - Kelas 0 dan Kelas 1: **0.98**
- **Support**:
  - Kelas 0: **17,697 sampel**
  - Kelas 1: **17,369 sampel**
- **Jumlah total sampel**: **35,066 sampel**

Model ini mencapai tingkat **akurasi sebesar 97.86%** pada data uji, menunjukkan performa yang sangat baik. **Precision** untuk kelas 0 adalah **0.97** dan kelas 1 adalah **0.99**, sementara **recall** untuk kelas 0 mencapai **0.99** dan kelas 1 sebesar **0.97**. **F1-score** untuk kedua kelas adalah **0.98**, menunjukkan keseimbangan antara precision dan recall. Dengan total **35,066 sampel**, distribusi data cukup seimbang, yakni **17,697 untuk kelas 0** dan **17,369 untuk kelas 1**. Model ini mampu mengklasifikasikan kedua kelas dengan sangat baik.
"""